<!--
Google IO 2012 HTML5 Slide Template

Authors: Eric Bidelman <ebidel@gmail.com>
         Luke Mahé <lukem@google.com>

URL: https://code.google.com/p/io-2012-slides
-->
<!DOCTYPE html>
<html>
<head>
  <title>Lions and Tigers and Pig Ohh My</title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
  <!--This one seems to work all the time, but really small on ipad-->
  <!--<meta name="viewport" content="initial-scale=0.4">-->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
  <script data-main="js/slides" src="js/video.js"></script>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">
  <slide class="logoslide nobackground">
    <article class="flexbox vcenter">
     	 <span><img src="images/logoWes.png" /></span>
    </article>
  </slide>

  <slide class="title-slide segue nobackground">
	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <aside class="gdbar"><img src="images/pdc-sml.png" ></aside>
    <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
    </hgroup>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <article>
     	<span class="build">
	     	<img id="li-image5" src="/images/ford.png">
	 		<img id="li-image2" src="/images/predicting_oscars.png">
	 		<img id="li-image4" src="/images/kreditech.png">
			<img id="li-image1" src="/images/whitehouse.png">
			<img id="li-image3" src="/images/bigdata_trust.png">
			<img id="li-image6" src="/images/questioning_bigdata.png">
			<img id="li-image7" src="/images/data_anarchy.png">
			<img id="li-image8" src="/images/jobs.png">
	    </span>
    </article>
  </slide>


  <slide class="fill nobackground" style="background-image: url(images/judy-garland-confused.jpg)">
    <hgroup>
      <h2 class="white italics" style="text-shadow: 1px 1px 1px #000;">"What's the Big Deal?"</h2>
    </hgroup>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Definition</h2>
    </hgroup>
    <article>
      <div style="position: absolute; top: 20px; right:90px;text-align:right;width:60%">
		<span class="italics">Big data is the term for a collection of data sets so large and complex that it becomes difficult to process using on-hand database management tools or traditional data processing applications... The trend to larger data sets is due to the additional information derivable from analysis of a single large set of related data, as compared to separate smaller sets with the same total amount of data, allowing correlations to be found to "spot business trends, determine quality of research, prevent diseases, link legal citations, combat crime, and determine real-time roadway traffic conditions.</span>
	  </div>
	 
	  <ol class="build" style="position:relative; top: 200px;">
		<li><b style="font-size: 30pt">Volume</b></li>
		<li><b style="font-size: 30pt">Velocity</b></li>
		<li><b style="font-size: 30pt">Variety</b></li>
		<img id="arrow" src="images/arrow-vector-sml.png">
		<img id="vs" src="images/BigData-4Vs.png">
	  </ol>	
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
 	<hgroup>
      <h2>Example</h2>
    </hgroup>
    <article class="smaller">
		  <img src="images/737.png" />
			
			<ul>
				  <li>1 Boeing 737 engine generates 20 terabytes of data an hour. Each aircraft has two of those engines. That’s 40 TB of data an hour. </li>
				  <li>So in a standard 6 hour cross country flight, you are talking 240 TB of new data.</li>
				  <li>Now multiply that with the number of flights for all commercial jetliners daily in the US.</li>
				  <li>For Southwest Airlines alone... Total data generated every day by Southwest Airlines’ fleet of 607 Boeing 737 aircraft:<br /> (20TB/ hr x 10.8hr avg operation per day) x 2 engines x 607 = <br />262,224 terabytes (or 256 petabytes) PER DAY</li>
			 </ul>
			<div style="position: absolute; bottom:20px; left: 50px;"class="source black">
				http://avoa.com/2014/01/20/are-enterprises-prepared-for-the-data-tsunami/
			</div>
	      
    </article>
  </slide>

<slide class="fill nobackground" style="background-image: url(/images/2012-bigdata.png)">
    <hgroup>
      <h2>2012</h2>
    </hgroup>
		<div style="position: absolute; bottom:20px; left: 50px;"class="source black">
			http://magazine.good.is/infographics/the-world-of-data-we-re-creating-on-the-internet#open
		</div>
  </slide>


 <slide class="fill nobackground" style="background-image: url(/images/internet-minute.png)">
    <hgroup>
      <h2>2015</h2>
    </hgroup>
		<div style="position: absolute; bottom:20px; left: 50px;"class="source black">
			http://www.intel.com/content/www/us/en/communications/internet-minute-infographic.html
		</div>
  </slide>


 <slide class="fill nobackground">
    <hgroup>
      <h2>Increase 2012-2014</h2>
    </hgroup>
	<article>
		<table>
			<tr>
				<th></th>
				<th>2012</th>
				<th>2014</th>
				<th>Diff</th>
			</tr>
			<tr>
				<td>Mobile Traffic consumed / mnth</td>
				<td>1.5 exabytes</td>
				<td>2.5 exabytes</td>
				<td>69% increase</td>
			</tr>
			<tr>
				<td>Video Uploaded to YouTube / min</td>
				<td>20 hrs</td>
				<td>100 hrs</td>
				<td>5X More</td>
			</tr>
			<tr>
				<td>Tweets / min</td>
				<td>34,722</td>
				<td>347,222</td>
				<td>10X More</td>
			</tr>
		
		</table>
	</article>	
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <article>
	    <section>
			<b>Warning!!!</b><br/><br/>
			<center>
	        <img src="images/tornado_warning-789137.gif" width="50%"/>
			</center>
		</section>		
    </article>  
  </slide>
 
  <slide class="fill nobackground" style="background-image: url(/images/the_wizard_of_oz.jpg)">
    <hgroup>
      <h2 class="white" style="text-shadow: 1px 1px 1px #000;">How can we deal with all this data?</h2>
    </hgroup>
  </slide>


  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<article>
     	<span> 
			<img id="hadoop" src="/images/hadoop-elephant.jpeg" width="500" height="375" alt="Hadoop" />
			<span id="hadoopDef">Apache Hadoop is an open-source software framework that supports data-intensive distributed applications, licensed under the Apache v2 license. It supports the running of applications on large clusters of commodity hardware.<br /><br />Windows Azure HDInsight provides ease of management, agility and an open Enterprise-ready Hadoop service in the cloud.
			</span>
	    </span>
    </article>
	<aside class="note">
      <section style="font-size: 12pt !important">
       The name my kid gave a stuffed yellow elephant. Short, relatively easy to spell and pronounce, meaningless, and not used elsewhere: those are my naming criteria. Kids are good at generating such. Googol is a kid’s term.
      </section>
    </aside>
  </slide>

<slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Agenda</h2>
    </hgroup>
    <article>
     	<ul class="build">
			<li>Setup the Problem Space</li>
			<li>Define HADOOP and it's core Technologies</li>
			<li>Demo/Discuss Wordcount</li>
			<li>Demonstrate Running Locally using Cloudera's Single-Node Hadoop Cluster 
				(or HDInsight Emulator for Microsoft Azure for .NET Track)</li>
			<li>Demo/Discuss MaxTemperature in Java / C#</li>
			<li>Demo/Discuss MaxTemperature in Pig Latin</li>
			<li>Demo/Discuss MaxTemperature in Hive</li>
			<li>Discuss Cloud Offerings</li>
			<li>Wrapup</li>
	    </ul>
    </article>
  </slide>


  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>What is Hadoop? Mike Olson, Cloudera CEO</h2>
    </hgroup>
	<article>
     	<iframe id="ytplayer" type="text/html" width="640" height="390"
		  src="http://www.youtube.com/embed/qNP4_ICDeqE?start=10"
		  frameborder="0"></iframe>
		<footer class="source" style="position:absolute; bottom:10px">Silicon Angle. (Jan 28, 2011) “What is Hadoop? Hadoop 101 with Mike Olsen” Retrieved from http://www.youtube.com/watch?v=qNP4_ICDeqE</footer>
    </article>
  </slide>


  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>What is Hadoop Composed of?</h2>
    </hgroup>
	<article class="smaller build">
			<span><b>HDFS:</b> HDFS is a distributed, scalable, and portable file system written in Java for the Hadoop framework. Each node in a Hadoop instance typically has a single namenode; a cluster of datanodes form the HDFS cluster. The situation is typical because each node does not require a datanode to be present. Each datanode serves up blocks of data over the network using a block protocol specific to HDFS. The file system uses the TCP/IP layer for communication. </span><br /><br />
			<span><b>MapReduce: </b> is a programming model for processing large data sets, and the name of an implementation of the model by Google. MapReduce is typically used to do distributed computing on clusters of computers.<br /><br />
			Writing a parallel-executable program has proven over the years to be a very challenging task. MapReduce simples the process by requiring coders to write only the simpler Map() and Reduce() functions, which focus on the logic of the specific problem at hand, while the "MapReduce System" handles the marshalling of the distributed servers, running the various tasks in parallel, managing all communications and data transfers between the various parts of the system, providing for redundancy and failures, and overall management of the whole process.<br /><br />
			</span>
    </article>
 	<aside class="note">
      <section style="font-size: 12pt !important">
       MapReduce: The model is inspired by the map and reduce functions commonly used in functional programming, although their purpose in the MapReduce framework is not the same as their original forms<br />
       2003 google published papers on the google file system and mapreduce

      </section>
    </aside>
  </slide>

  <slide class="fill nobackground" style="background-image: url(/images/hadoop_arch.png)">
	<footer class="source" style="position:absolute; bottom:10px"><a class="blue" href="http://bigdata.globant.com/wp-content/uploads/2012/05/hadoop_hdfs1.png">http://bigdata.globant.com/wp-content/uploads/2012/05/hadoop_hdfs1.png</a></footer>
  </slide>


  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>HDFS Features</h2>
    </hgroup>
	<article class="build">
		<ul>
			<li>Designed to store large files</li> 
			<li>Fault tolerant and self-healing distributed file system</li>
			<li>Stores files as large blocks (64 to 128 MB) </li>
			<li>Each block stored on multiple servers </li>
			<li>Data is automatically re-replicated on need </li>
			<li>Accessed from command line, Java API, C API, and... C#</li>
		</ul>
    </article>
  </slide>

 <slide class="fill nobackground" style="background-image: url(images/demo.png)">
    <hgroup>
      <h2 class="white italics" style="text-shadow: 1px 1px 1px #000;">Demo</h2>
    </hgroup>
	<aside class="note" style="position:relative; top: -300px;">
      <section style="font-size: 12pt !important">
	     Interacting with the hadoop file system
         1017  hadoop fs -ls /user/cloudera <br />
		 1018  hadoop fs -ls /home/cloudera/ncdc<br />
		 1019  hadoop fs -mkdir /home/cloudera/sample<br />
		 1020  hadoop fs -ls /home/cloudera/sample<br />
		 1021  hadoop fs -ls /home/cloudera<br />
		 1022  echo "Hello Cloudera VM" > testFile.txt<br />
		 1023  ls -lrta<br />
		 1028  hadoop fs -ls /home/cloudera/<br />
		 1030  hadoop fs -put testFile.txt /home/cloudera/sample<br />
		 1031  hadoop fs -ls testFile.txt /home/cloudera/sample/<br />
		 1033  hadoop fs -get /home/reiszwt/cloudera/testFile.txt /tmp<br />
		 1034  ls -ltra /tmp<br />
		       hadoop fs -conf=conf/hadoop-cluster.xml -ls /home/<br />
      </section>
    </aside>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>What is MapReduce</h2>
    </hgroup>
	<article class="smaller">
		<p><b>MapReduce: </b> is a programming model for processing large data sets, and the name of an implementation of the model by Google. MapReduce is typically used to do distributed computing on clusters of computers.</p>
		<p>Writing a parallel-executable program has proven over the years to be a very challenging task. MapReduce simples the process by requiring coders to write only the simpler Map() and Reduce() functions, which focus on the logic of the specific problem at hand, while the "MapReduce System" handles the marshalling of the distributed servers, running the various tasks in parallel, managing all communications and data transfers between the various parts of the system, providing for redundancy and failures, and overall management of the whole process.</p>
		<p>
		Not new concept (Just wasn't in parrallel):
		<article class="smaller">
	      <pre class="prettyprint" data-lang="bash">
     #!/usr/bin/env bash
     for year in ../input/ncdc/all/*
     do
        echo -ne `basename $year .gz`"\t"
        gunzip -c $year | \
        awk '{ temp = substr($0, 88, 5) + 0;
        if (temp !=9999 && q ~ /[01459]/ && temp > max) max = temp }
        END { print max }'
     done
		  </pre>
	    </article>
		</p>	
		</span>
    </article>
  </slide>


  <slide class="fill nobackground" style="background-image: url(/images/Mapreduce_Overview.png)">
    <hgroup>
      <h2 class="black" style="text-shadow: 1px 1px 1px #000;">Mapreduce Overview</h2>
    </hgroup>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Map Reduce Features</h2>
    </hgroup>
	<article class="smaller">
   		<ul>
			<li>Fine grained Map and Reduce tasks</li> 
			<ul>
				<li>Improved load balancing</li> 
				<li>Faster recovery from failed tasks </li> 
			</ul>
			<li>Automatic re-execution on failure </li> 
			<ul>
				<li>In a large cluster, some nodes are always slow or flaky </li> 
				<li>Introduces long tails or failures in computation </li> 
				<li>Framework re-executes failed tasks</li> 
			</ul>
			<li>Locality optimizations </li> 
			<ul>
				<li>With big data, bandwidth to data is a problem </li> 
				<li>Map-Reduce + HDFS is a very effective solution </li> 
				<li>Map-Reduce queries HDFS for locations of input data </li> 
				<li>Map tasks are scheduled local to the inputs when possible</li> 
			</ul>	
		</ul>
		<footer class="source" style="position:absolute; bottom:10px">http://www.cs.wright.edu/~tkprasad/courses/cs707/ProgrammingHadoop.pdf</footer>
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Putting it All Together With Hadoop's Version of Hello World</h2>
    </hgroup>
	<article >
   		“45% of all Hadoop tutorials count words. 25% count 
		sentences. 20% are about paragraphs. 10% are log 
		parsers. The remainder are helpful.” <br />
		-jandersen @http://twitter.com/jandersen/ <br /> <br />
		<ul>
			<li>Talk about how to create a local HADOOP Environment using Microsoft Technology</li>
			<li>Copy Some data into the HDFS</li>
			<li>Execute some code (Using Visual Studio & C#)</li>
			<li>Count some Words!</li>
		</ul>
    </article>
  </slide>


  <slide class="fill nobackground" style="background-image: url(images/demo.png)">
    <hgroup>
      <h2 class="white italics" style="text-shadow: 1px 1px 1px #000;">Demo</h2>
    </hgroup>
	<aside class="note" style="position:absolute; top:-300px;left:0px">
      <section style="font-size: 12pt !important">
	      <br /> (Java Version)
	   	    <br /> cat bible+shakes.nopunc | wc -l
			<br /> cat bible+shakes.nopunc | wc -w
			<br /> tail -1000 bible+shakes.nopunc 
			<br /> head -1000 bible+shakes.nopunc
			<br /> ------------
			<br /> hadoop fs -ls /user/cloudera/
			<br /> hadoop fs -mkdir /user/cloudera/bible
			<br /> hadoop fs -put bible+shakes.nopunc /user/cloudera/bible
			<br /> hadoop fs -ls /user/cloudera/bible
			<br /> 
			<br /> hadoop fs -ls /user/cloudera/bible
			<br /> hadoop jar WordCount-0.0.1-SNAPSHOT.jar com.wesleyreisz.bigdata.wordcount.v1.WordCount 
			<br />           /user/cloudera/bible/bible+shakes.nopunc 
			<br />           /user/cloudera/bible/output
			<br /> ------------
			<br /> hadoop fs -ls /user/cloudera/bible/output
			<br /> hadoop fs -cat /user/cloudera/bible/output/part-00000
			<br /> mkdir working
			<br /> cd working/
			<br /> hadoop fs -get /user/cloudera/bible/output/part* 
			<br /> cat part-00000 
			<br /> sort -nk2 part-00000 
		  <br /> (.NET Version)
		    <br />run in VS
			<br />hadoop fs -get Output/wordcount/part* .
            <br />linux: sort -k2 -n part-00000
            <br />ps: Get-Content .\part-00000 | Sort-Object { [double]$_.split()[-1] } -Descending
	  </section>
    </aside>
  </slide>

 <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Setting up Enviornments</h2>
    </hgroup>
    <article>
     	<span class="build">
			<p>
	     		For java, all you need is maven, Java (I'm using 7), and the VM from Cloudera (or an installed environment for hadoop) 
			</p>
			<p>
				For .NET, you can install the HDInsight Emulator and configure Visual Studio with some NuGet plugins. The next couple of
				slides talk specifically about .NET and C#.
			</p>	
	    </span>
    </article>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Installing HDInsight Emulator</h2>
    </hgroup>
    <article>
     	<span class="build">
	     	<img id="li-image5" src="/images/installHDIE_slide1.png">
	 		<img id="li-image2" src="/images/installHDIE_slide2.png">
	 		<img id="li-image4" src="/images/installHDIE_slide3.png">
			<img id="li-image1" src="/images/hadoop-installed.png">
			<img id="li-image3" src="/images/cmd.png">
	    </span>
    </article>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Setting Up Visual Studio</h2>
    </hgroup>
	<article >
   		<ul class="build">
			<li>Startup Visual Studio</li>
			<li>Create a Console App</li>
			<li>Use NuGet to add Microsoft .NET API for Hadoop, Map Reduce API for Hadoop, & Hadoop Web Client</li>
			<li>Let's See Some Code </li>
		</ul>
    </article>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <hgroup>
      <h2>WordCount::Map Function</h2>
    </hgroup>
	    <article class="smaller">
		  <center>
		  	<button class="swapJava">Toggle C#/Java</button>
		  </center>
		  <pre class="prettyprint swapCode" data-lang="c#">
  public class WordCountMapper : MapperBase
  {
      private static int one = 1;
      public override void Map(string inputLine, MapperContext context)
      {
          string[] words = inputLine.Split(' ');
          foreach (String word in words) {
              if (word.Length>1) {
                  //outputs each word into a single line with the number 1
                  //skip spaces
                  context.EmitKeyValue(word, one.ToString());
              }
          }
      }
  }		
		  </pre>
		  <pre class="prettyprint swapCode" style="display: none" data-lang="java">
  public static class Map extends MapReduceBase 
   	implements Mapper<LongWritable, Text, Text, IntWritable> {
     private final static IntWritable one = new IntWritable(1);
     private Text word = new Text();

     public void map(LongWritable key, Text value, 
   		  OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException {
       String line = value.toString();
       StringTokenizer tokenizer = new StringTokenizer(line);
       while (tokenizer.hasMoreTokens()) {
         word.set(tokenizer.nextToken());
         output.collect(word, one);
       }
     }
   }		
		</pre>
	    </article>
	    <article>
			<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
		</article>	
    </article>
  </slide>


<slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <hgroup>
      <h2>WordCount::Flow</h2>
    </hgroup>
	    <article class="smaller">
			<img src="/images/fruit.png">
	    </article>	
    </article>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <hgroup>
      <h2>WordCount::Reduce Function</h2>
    </hgroup>
	    <article class="smaller">
			<center>
			  	<button class="swapJava">Toggle C#/Java</button>
			</center>
			<pre class="prettyprint swapCode" data-lang="c#">
    public class WordCountReducer : ReducerCombinerBase
    {
        public override void Reduce(string key, IEnumerable<string> values, ReducerCombinerContext context)
        {
            //sum all the ones
           int sum = 0;
           foreach(String value in values)
           {
              sum += int.Parse(value);
           }
           context.EmitKeyValue(key, sum.ToString());
        }
    }		
			  </pre>
	      <pre class="prettyprint swapCode" style="display: none" data-lang="java">
    public static class Reduce extends MapReduceBase 
    	implements Reducer<Text, IntWritable, Text, IntWritable> {
      public void reduce(Text key, Iterator<IntWritable> values, 
    		  OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException {
        int sum = 0;
        while (values.hasNext()) {
          sum += values.next().get();
        }
        output.collect(key, new IntWritable(sum));
      }
    }		
		  </pre>
	    </article>	
    </article>
    <article>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	</article>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <hgroup>
      <h2>WordCount::Flow</h2>
    </hgroup>
	    <article class="smaller">
			<img src="/images/fruit.png">
	    </article>	
    </article>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <hgroup>
      <h2>WordCount::Driver</h2>
    </hgroup>
	    <article class="smaller">
	      	  <center>
			  	<button class="swapJava">Toggle C#/Java</button>
			  </center>
			  <pre class="prettyprint swapCode" data-lang="c#">
	public class WordCountjob : HadoopJob<WordCountMapper, WordCountReducer>
	{
	    public override HadoopJobConfiguration Configure(ExecutorContext context)
	    {
	        HadoopJobConfiguration config = new HadoopJobConfiguration();
	        config.InputPath = "Input/wordcount";
	        config.OutputFolder = "Output/wordcount";
	        return config;
	    }
	}
	static void Main(string[] args)
	{
	    var hadoop = Hadoop.Connect();
	    var result = hadoop.MapReduceJob.ExecuteJob<WordCountjob>();

	    Console.In.Read();
	}		
			  </pre>
			  <pre class="prettyprint swapCode" style="display: none" data-lang="java">
    public static void main(String[] args) throws Exception {
       JobConf conf = new JobConf(WordCount.class);
       conf.setJobName("wordcount");

       conf.setOutputKeyClass(Text.class);
       conf.setOutputValueClass(IntWritable.class);

       conf.setMapperClass(Map.class);
       conf.setCombinerClass(Reduce.class);
       conf.setReducerClass(Reduce.class);

       conf.setInputFormat(TextInputFormat.class);
       conf.setOutputFormat(TextOutputFormat.class);

       FileInputFormat.setInputPaths(conf, new Path(args[0]));
       FileOutputFormat.setOutputPath(conf, new Path(args[1]));

       JobClient.runJob(conf);
    }		
		  </pre>
	    </article>	
	
    </article>
    <article>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	</article>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <hgroup>
      <h2>Compile and Run It (Java)</h2>
    </hgroup>
	    <article class="smaller">
	      <pre class="prettyprint" data-lang="xml">		
  &lt;dependencies&gt;
      &lt;dependency&gt;
          &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
          &lt;artifactId&gt;hadoop-core&lt;/artifactId&gt;
          &lt;version&gt;1.1.2&lt;/version&gt;
      &lt;/dependency&gt;
   &lt;/dependencies&gt;
		  </pre>
		
		<pre class="prettyprint" data-lang="bash">		
mvn clean install 
export target/ 
hadoop jar WordCount-0.0.1-SNAPSHOT.jar com.wesleyreisz.bigdata.wordcount.v1.WordCount \
	/home/reiszwt/samples/bible/bible+shakes.nopunc /home/reiszwt/samples/bible/output
	  </pre>
	    </article>	
    </article>
    <article>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	</article>
  </slide>

  <slide class="fill nobackground" style="background-image: url(images/runit_sml.png)">
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <hgroup>
      <h2 class="italics" style="text-shadow: 1px 1px 1px #000;">Compile and Run it (C#)</h2>
    </hgroup>
  </slide>

  <slide class="fill nobackground" style="background-image: url(images/scarecrow.jpg)">
    <hgroup>
      <h2 class="white italics" style="text-shadow: 1px 1px 1px #000;">"I have an idea... let's build something!"</h2>
    </hgroup>
  </slide>

  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>National Climatic Data Center (NCDC) Weather Station Data</h2>
    </hgroup>
	<article >
   		<p>Purpose: Write a Program to Grab the Highest Temperatures over a large volume of Datasets from NCDC</p>
		<p>In the process, we will:</p>
		<ul>
			<li>Write <b>AND TEST</b> using sample data</li>
			<li>Test against the local filesystem</li>
			<li>Test against the localhost installation of hadoop</li>
			<!--
			<li>Copy data into the remote hdfs cluster and execute it</li>
			-->
		</ul>
    </article>
  </slide>
  
  <slide>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>National Climatic Data Center (NCDC) Weather Station Data</h2>
    </hgroup>
	<article >
   		<pre class="prettyprint" data-lang="text">
0029029720999991901072213004+60450+022267FM-12+001499999V0200201N001019999999N0000001N9+03171+99999101681ADDGF101991999999999999999999			
		</pre>	
	   		<a href="http://www1.ncdc.noaa.gov/pub/data/noaa/ish-format-document.pdf
	    ">http://www1.ncdc.noaa.gov/pub/data/noaa/ish-format-document.pdf</a>
		<p>
		    POS: 88-92<br />
		    AIR-TEMPERATURE-OBSERVATION air temperature<br />
		    The temperature of the air.<br />
		    MIN: -0932 MAX: +0618 UNITS: Degrees Celsius<br />
		    SCALING FACTOR: 10<br />
		    DOM: A general domain comprised of the numeric characters (0-9), a plus sign (+), and a minus10
		    sign (-).<br />
		    +9999 = Missing<br />
		</p>

        <pre>
			//verify data
			gunzip 1901.gz
			cat 1901 | cut -c88-92 | sort 
		</pre>	
		
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Steps</h2>
    </hgroup>
	<article>
   	<pre >	
# show project in IntelliJ 
# discuss maven
# discuss testcases

(Java Way)
# build it & run local
hadoop jar target/hadoop-examples.jar com.wesleyreisz.lionsAndTigersAndPig.MaxTemperatureDriver 
--conf ../../conf/hadoop-local.xml ../../input/ncdc/all/ output
# build it & run localhost
hadoop jar target/hadoop-examples.jar com.wesleyreisz.lionsAndTigersAndPig.MaxTemperatureDriver 
--conf ../../conf/hadoop-localhost.xml  /user/cloudera/ncdc/input  /user/cloudera/ncdc/output

	</pre>
    </article>
 <article>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	</article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Steps</h2>
    </hgroup>
	<article>
   	<pre >	
(.NET Way)
http://www.windowsazure.com/en-us/manage/services/hdinsight/submit-hadoop-jobs-programmatically/
configure core-site.xml for azure (when needed)
first make sure the old output is removed:

hadoop fs -rmr Output/ncdc

hadoop jar %HADOOP_HOME%\lib\hadoop-streaming.jar 
  -conf={path to core-site.xml}
  -input "Input/ncdc" 
  -output "Output/ncdc" 
  -file "C:\Users\Wes\projects\lionsAndTigersAndPigOhhMy\dotnet\MaxTemperatureMapper\bin\Debug\MaxTemperatureMapper.exe"
	</pre>
    </article>
 <article>
		<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	</article>
  </slide>

<!--
  <slide class="fill nobackground" style="background-image: url(images/hpcloud.png)">
    <hgroup>
      <h2 class="black italics" style="text-shadow: 1px 1px 1px #000;">Build a Remote Server with Cloud Technology</h2>
    </hgroup>
  </slide>

 <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Create Servers</h2>
    </hgroup>
	<article >
		<img src="/images/step1CreateServers.png">
    </article>
  </slide>

 <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>SSH into Cloudera Manager Server</h2>
    </hgroup>
	<article >
		<img src="/images/step3GrabInstaller.png">
    </article>
  </slide>

<slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Install Cloudera Manager</h2>
    </hgroup>
	<article>
		<img src="/images/launchCM.png">
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Install Cloudera Manager</h2>
    </hgroup>
	<article>
		<img src="/images/installingJdk.png">
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Install Cloudera Manager</h2>
    </hgroup>
	<article>
		<img src="/images/point.png">
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Install Cloudera Manager</h2>
    </hgroup>
	<article>
		<img src="/images/logon.png">
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Install Cloudera Manager</h2>
    </hgroup>
	<article>
		<img src="/images/installFree.png">
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Add Servers To Cluster</h2>
    </hgroup>
	<article>
		<img src="/images/addServers2Cluster.png">
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Add Servers To Cluster</h2>
    </hgroup>
	<article>
		<img src="/images/installed.png">
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Add Servers To Cluster</h2>
    </hgroup>
	<article>
		<img src="/images/validated.png">
    </article>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Great Video on the Install Process for a Cloudera Cluster</h2>
    </hgroup>
	<article >
		<article>
			<img src="/images/youtubeInstallClouderaManager.png"><br />
			<a style="color: #999;" href="http://www.youtube.com/watch?v=CobVqNMiqww">http://www.youtube.com/watch?v=CobVqNMiqww</a>
	    </article>
    </article>
  </slide>

 <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Deploy Your Code to the Cloud</h2>
    </hgroup>
	<article >
		<article>
			<pre class="prettyprint" data-lang="bash">	
   49  sudo -u hdfs hadoop fs -ls /home/hdfs
   50  sudo -u hdfs hadoop fs -ls /home/hdfs/ncdc
   51  export HADOOP_CLASSPATH=/home/hdfs/
   53  sudo -u hdfs hadoop jar /home/hdfs/hadoop-examples.jar 
       com.wesleyreisz.lionsAndTigersAndPig.MaxTemperatureDriver /home/hdfs/ncdc/in /home/hdfs/ncdc/out
   56  hadoop fs -ls /home/hdfs/ncdc/out/
   57  hadoop fs -cat /home/hdfs/ncdc/out/part*				
			</pre>
	    </article>
    </article>
  </slide>
-->

<slide class="fill nobackground" style="background-image: url(images/demo.png)">
   <hgroup>
     <h2 class="white italics" style="text-shadow: 1px 1px 1px #000;">Demo</h2>
   </hgroup>
 </slide>
 
 <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
<hgroup>
     <h2>There are also other SAAS Solutions using Hadoop</h2>
   </hgroup>
<article >
	Amazon
	<ul>
		<li>EC2 has both IAAS and SAAS offerings</li>
		<li>S3 is an HDFS Filesystem... you can read as input anything loaded there and write it back out</li>
	</ul>
	Microsoft
	<ul>
		<li>Azure has HDInsight</li>
	</ul>
	Google
	<ul>
		<li>Click to Deploy</li>
		<li>Uses buckets as storage</li>
		<li>gcloud compute ssh --zone=<hadoop-master-zone> <hadoop-master> \
 --ssh-flag="-t" --command="sudo su -l hadoop"</li>
	</ul>	
   </article>
<aside class="note">
     <section style="font-size: 12pt !important">
  </section>
   </aside>
 </slide>
 

  <slide class="fill nobackground" style="background-image: url(images/lion1.jpg)">
    <hgroup>
      <h2 class="white italics" style="text-shadow: 1px 1px 1px #000;">"What!? What happened to Pig?"</h2>
    </hgroup>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Different Ways to Write your Hadoop Queries</h2>
    </hgroup>
	<article >
		<ul>
			<li>Java/C/C#</li>
			<li>Pig</li>
			<li>Hive</li>
		</ul>
    </article>
	<aside class="note">
      <section style="font-size: 12pt !important">
	  </section>
    </aside>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Pig's Philosophy</h2>
    </hgroup>
	<article class="smaller">
		<p>
		<b>What does it mean to be a pig?</b><br />
		The Apache Pig Project has some founding principles that help pig developers decide how the system should grow over time. This page presents those principles.
		</p>
		<p>
		<b>Pigs Eat Anything</b><br />
		Pig can operate on data whether it has metadata or not. It can operate on data that is relational, nested, or unstructured. And it can easily be extended to operate on data beyond files, including key/value stores, databases, etc.
		</p>
		<p>
		<b>Pigs Live Anywhere</b><br />
		Pig is intended to be a language for parallel data processing. It is not tied to one particular parallel framework. It has been implemented first on Hadoop, but we do not intend that to be only on Hadoop.
		</p>
		<p>
		<b>Pigs Are Domestic Animals</b><br />
		Pig is designed to be easily controlled and modified by its users.
		</p>
		<p>
		<b>Pigs Fly</b><br />
		Pig processes data quickly. We want to consistently improve performance, and not implement features in ways that weigh pig down so it can't fly.
		</p>
		<p>http://pig.apache.org/</p>
    </article>
	<aside class="note">
      <section style="font-size: 12pt !important">
	  </section>
    </aside>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Let's Take a Look at Pig</h2>
    </hgroup>
	<article >
		<pre class="prettyprint" data-lang="shell">
c:\Hadoop\hadoop-1.1.0-SNAPSHOT>pig
2013-11-20 21:46:25,949 [main] INFO  org.apache.pig.backend.hadoop.executionengi
ne.HExecutionEngine - Connecting to map-reduce job tracker at: localhost:50300
grunt>
		</pre>
		<pre class="prettyprint" data-lang="pig latin">
records= LOAD '/user/Wes/Input/sample/sample.txt' AS (year:chararray, temperature:int, quality:int);
filtered_records =  FILTER records  By temperature !=9999 AND quality==1;
grouped_recrds = GROUP filtered_records by year;
max_temp = FOREACH grouped_recrds GENERATE group, MAX(filtered_records.temperature);
dump max_temp;			
		</pre>
		<img src="/images/pig_open.png">
    </article>
	<aside class="note">
      <section style="font-size: 12pt !important">
	  </section>
    </aside>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Hive's Approach</h2>
    </hgroup>
	<article class="smaller">
		<p>
			<b>Apache Hive</b><br />
			The Apache HiveTM data warehouse software facilitates querying and managing large datasets residing in distributed storage. Built on top of Apache HadoopTM , it provides
			</p>
			<p>
			<b>Tools to enable easy data extract/transform/load (ETL)</b><br />
			A mechanism to impose structure on a variety of data formats Access to files stored either directly in Apache HDFSTM or in other data storage systems such as Apache HBase
			</p>
			<p>
			<b>Query execution via MapReduce</b><br />
			Hive defines a simple SQL-like query language, called QL, that enables users familiar with SQL to query the data. At the same time, this language also allows programmers who are familiar with the MapReduce framework to be able to plug in their custom mappers and reducers to perform more sophisticated analysis that may not be supported by the built-in capabilities of the language. QL can also be extended with custom scalar functions (UDF's), aggregations (UDAF's), and table functions (UDTF's).
		</p>
		<p>
			Hive is not designed for OLTP workloads and does not offer real-time queries or row-level updates. It is best used for batch jobs over large sets of append-only data (like web logs). What Hive values most are scalability (scale out with more machines added dynamically to the Hadoop cluster), extensibility (with MapReduce framework and UDF/UDAF/UDTF), fault-tolerance, and loose-coupling with its input formats.
	</p>
		<p>https://cwiki.apache.org/confluence/display/Hive/Home</p>
    </article>
	<aside class="note">
      <section style="font-size: 12pt !important">
	  </section>
    </aside>
  </slide>


  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Let's Take a Look at Hive</h2>
    </hgroup>
	<article >
		<pre class="prettyprint" data-lang="bash">
hive
		</pre>
		<pre class="prettyprint" data-lang="hive">
LOAD DATA LOCAL INPATH 'Input/ncdc/micro-tab/sample.txt' OVERWRITE INTO Table records;
select  year, MAX(temperature) FROM records where temperature != 9999 and quality==1 group by year;
		</pre>
		<article style="position:absolute; right: 20px; bottom: 20px;"><img src="/images/hiveSml.png" /></article>
    </article>
	<aside class="note">
      <section style="font-size: 12pt !important">
	  </section>
    </aside>
  </slide>

  <slide class="fill nobackground" style="background-image: url(images/witch.jpg)">
    <hgroup>
      <h2 class="white italics" style="text-shadow: 1px 1px 1px #000;">But wait... we're not quite done now are we?'</h2>
    </hgroup>
  </slide>

  <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Hadoop is a massive</h2>
    </hgroup>
	<article >
			<center>
			  	<button class="swapJava">Toggle Cloudera/HDInsight</button><br /><br />
			  </center>
			  <div class="swapCode" data-lang="c#">
					<center><img src="/images/hdinsightEcosystem.jpg"></center>
			  </div>
			   <div class="swapCode" style="display: none" data-lang="java">
   					<center><img src="/images/ecosystem.png"></center>
			  </pre>			
		  </pre>
	</article>
  </slide>

 <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Summary </h2>
    </hgroup>
	<article >
			<ul>
				<li>Hadoop Ecosystem is Huge</li>
				<li>Support multiple ways to get and work with data, depending on your needs and skills</li>
				<li>Is Based in Open Source!!!</li>
				<li>Based on Java, but can be used in .NET!</li>
				<li>Documentation is weak still...</li>
				<li>Multitude of options from local machines to IAAS and SAAS offerings</li>
				<li>The market potential is huge with IoT and Big Data... worth knowing the basics</li>
			</ul>
    </article>
	<aside class="note">
      <section style="font-size: 12pt !important">
	  </section>
    </aside>
  </slide>

 <slide>	<a href="https://github.com/wesreisz/lionsAndTigersAndPigOhhMy"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
	<hgroup>
      <h2>Shoutouts </h2>
    </hgroup>
	<article>
		<table>
			<tr>
				<td width="250px"><img src="/images/hadoopBookSml.png" width="231px" height="300px"></td>
				<td vertical-align:top;>
					Hadoop: The Definitive Guide, 3rd Edition<br />
					Storage and Analysis at Internet Scale<br />
					By Tom White<br />
					Publisher: O'Reilly Media / Yahoo Press<br />
					Released: May 2012<br /><br />
					*NCDC Samples came directly from this book<br>
http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white_paper_c11-520862.html
					
				</td>
			</tr>
			<tr>
				<td width="250px"><img src="/images/clouderaLogo.png" width="184px" height="75px"></td>
				<td vertical-align:top;>
					<b><a style="color: #999" href="http://www.cloudera.com/">http://www.cloudera.com</a></b><br />
					Provided VM I used<br />
					Provided Installed for the Cloud Deployed Cluster<br />
					Wonderful help via google Group Forums @ <a href="https://groups.google.com/a/cloudera.org/groups/dir">https://groups.google.com/a/cloudera.org/groups/dir</a><br />
					Special Shoutout to <b>Sandy Ryza</a> of Cloudera for helping me with an issue I had with the CDH VM! Thank you!!!
				</td>
			</tr>

		</table>	
    </article>
	<aside class="note">
      <section style="font-size: 12pt !important">
	  </section>
    </aside>
  </slide>

  <slide class="fill nobackground" style="background-image: url(images/group.png)">
    <hgroup>
      <h2 class="white italics" style="text-shadow: 1px 1px 1px #000;"></h2>
    </hgroup>
	<article class="build">
		<img id="pigSml" width="400px" width="380" src="/images/computer_pig_logo-cartoon-pig.png" >
	</article>
  </slide>

  <slide class="thank-you-slide dark nobackground">
	<a href="https://github.com/wesreisz/Android-Wear-Whos-Next"><img border="0" class="gitfork" src="/images/forkme_right_red_aa0000.png" width="149px" height="149px" /></a>
    <aside class="gdbar right"><img src="images/pdc-sml.png"></aside>
    <article class="flexbox vleft auto-fadein">
      <h2>Thank You!</h2>
	  <p>Wesley Reisz</p>
	  <p class="auto-fadein" data-config-contact>
      </p>
    </article>    
  </slide>



<!-- end of the deck -->


  <slide class="backdrop"></slide>

</slides>

<script>
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-35519039-1']);
_gaq.push(['_trackPageview']);

(function() {
  var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>

<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body>
</html>
